{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Unsupervised Learning: Clustering and K-Means\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC October 2023\n",
    "<p>Phase 4</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from src.demo_images import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Goals\n",
    "- Assess what scenarios could use $k$-means\n",
    "- Articulate the methodology used by $k$-means\n",
    "- Apply KMeans from sklearn.cluster to a relevant dataset\n",
    "- Select the appropriate number of clusters using the elbow method and Silhouette Scores\n",
    "- Evaluate the weaknesses and remedies to $k$-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Often don't have labels on data:\n",
    "\n",
    "- Discover the structure in the data.\n",
    "- Is there some kind of grouping in the data?\n",
    "- Maybe discover relationship between subsets of the data \n",
    "- Its true dimensionality, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Goals are much less clear here:\n",
    "- We are not creating a prediction machine.\n",
    "- Instead we are recognizing patterns and uncovering relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Classic Scenario\n",
    "\n",
    ">You work for the marketing department within a large company that manages a customer base. \n",
    "For each customer you have a record of average purchase cost and time since last purchase.<br> \n",
    "You know that if you want to retain your customers you cannot treat them the same. You can use targeted marketing ads towards groups that demonstrate different behavior, but how will you divide the customers into groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Examples with clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are no training labels here. Just data points:\n",
    "    \n",
    "- Our eyes can make out regions.\n",
    "- But we want a computer to do this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.read_csv('Data/s1cluster.txt', delimiter = '\\s+ ', header = None, names = ['X1', 'X2'], engine = 'python')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'X1', y = 'X2', data = X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One example of some value:\n",
    "- recognizing/labeling and segmenting different types of cell tissue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/clustercells.png\" width = 600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Discretize image.\n",
    "- Clustering grid-cell in color-value space of RGB image\n",
    "- Discover regions of epithelial vs. non-epithelial cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another example might be segmenting customers into groups:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/cust_seg.jpg\" width = 500/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Discovering different types of customers within purchase data:\n",
    "\n",
    "- Could potentially segment into 4 groups?\n",
    "- Obviously targeted ads/deals, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### So what do you do with clustering results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Once clusters are identified:\n",
    "- Can use discovered clusters as a feature in a predictive task.\n",
    "- e.g., predict churn rate using customer cluster assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- *How were target labels in classification made in the first place?*\n",
    "\n",
    "- Discovered clusters becomes _**target labels**_:\n",
    "- Original data features and cluster assignment as training data for classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Our first clustering algorithm: KMeans\n",
    "- Assumes $K$ clusters\n",
    "- Assumes cluster centers (or centroids).\n",
    "- Assign each data points to each of the $K$ clusters\n",
    "    - pick cluster whose centroid is closest to data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'X1', y = 'X2', data = X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An iterative process:\n",
    "\n",
    "- Dont know cluster centroids.\n",
    "- Data points: don't know cluster assignments.\n",
    "\n",
    "#### Can help use one to find the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'X1', y = 'X2', data = X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Pick a random set of cluster center positions.\n",
    "- Assign clusters to data points\n",
    "- Data points and their cluster assignments:\n",
    "    - get mean of data in each cluster\n",
    "    - update centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/kmeans.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It can be shown the procedure lowers the cost function:\n",
    "\n",
    "$$L = \\sum_{i=1}^N \\sum_{k = 1}^K \\mathbb{1}(c_i = k)|x_i - \\mu_k|^2 $$\n",
    "\n",
    "where $ \\mathbb{1}(c_i = k) = 1$ if $x_i$ assigned to cluster $k$ else 0.\n",
    "\n",
    "- Cost function known as **inertia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>Kill iterations once convergence reached.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<img src = \"Images/kmeans_withobjective.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "KMeans is a distanced based algorithm. \n",
    "- We need to scale first then do the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()), \n",
    "         ('kmc', KMeans(n_clusters = 15, n_init = 'auto') ) ]\n",
    "kmc_pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kmc_pipe.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**KMeans attributes**\n",
    "\n",
    "- .cluster_centers_ attribute: fitted centroid locations\n",
    "- .labels_ attribute: cluster assignments for each data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The centers are scaled:\n",
    "- Need to unscale back to original data scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "scld_centers = kmc_pipe['kmc'].cluster_centers_\n",
    "kc_centers = kmc_pipe['scaler'].inverse_transform(scld_centers)\n",
    "\n",
    "# class labels for each observation\n",
    "class_assignment = kmc_pipe['kmc'].labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X['label'] = class_assignment\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Visualize cluster assigment/visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_palette(\"tab10\")\n",
    "\n",
    "sns.scatterplot(x = 'X1', y = 'X2', hue = 'label', palette=sns.color_palette('tab10', n_colors= 15), data = X)\n",
    "sns.scatterplot(x = kc_centers[:,0], y = kc_centers[:,1], color = 'blue', s = 80)\n",
    "#plt.legend([],[], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%capture clusterplot \n",
    "sns.set_palette(\"tab10\")\n",
    "\n",
    "sns.scatterplot(x = 'X1', y = 'X2', hue = 'label', palette=sns.color_palette('tab10', n_colors= 15), data = X)\n",
    "sns.scatterplot(x = kc_centers[:,0], y = kc_centers[:,1], color = 'blue', s = 80)\n",
    "#plt.legend([],[], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Class assignment for a given test point:\n",
    "- .predict() method for KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kmc_pipe.predict([[0.5e6 , 0.8e6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "clusterplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Elbow method: choosing the appropriate number of $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "KMeans inertia: can also get final value of loss function at convergence.\n",
    "- This is important: can help us use as a diagnostic tool. \n",
    "- Help us pick $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$L = \\sum_{i=1}^N \\sum_{k = 1}^K \\mathbb{1}(c_i = k)|x_i - \\mu_k|^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kmc_pipe['kmc'].inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Issue:\n",
    "- Adding more and more centroids (increasing K)\n",
    "- Arbitrarily decreases the convergence value of the inertia.\n",
    "- More centroids: much lower squared distance of a point to *some* centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$L = \\sum_{i=1}^N \\sum_{k = 1}^K \\mathbb{1}(c_i = k)|x_i - \\mu_k|^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define inertia vs K plotting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_inertias(X, K, increment, kmc_pipe):\n",
    "\n",
    "    klist = np.arange(1,K,increment)\n",
    "    inertia_list = []\n",
    "    for k in klist:\n",
    "        kmc_pipe.steps.pop(-1)\n",
    "        kmc_pipe.steps.append(('kmc', \n",
    "                               KMeans(\n",
    "                                   n_clusters = k, n_init = 'auto')))\n",
    "        kmc_pipe.fit(X)\n",
    "\n",
    "        inertia = kmc_pipe['kmc'].inertia_\n",
    "        inertia_list.append(inertia)\n",
    "        \n",
    "    plt.plot(klist, inertia_list)\n",
    "    plt.ylabel('Final inertia')\n",
    "    plt.xlabel('K')\n",
    "    plt.title('Elbow plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take in a very simple data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_simple = pd.read_csv('Data/xclara.txt').drop(columns = ['Unnamed: 0'])\n",
    "X_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'V1', y = 'V2', data = X_simple)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Optimal cluster number at/near elbow/kink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Inertia decreases sharply until it hits optimal cluster number:\n",
    "- Then increasing number makes marginal gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The behavior of inertia as a function of K is almost never this clean:\n",
    "- well separated clusters\n",
    "- similar sizes, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_inertias(X_simple, 30, 1, kmc_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example with our old dataset: a little less good.\n",
    "\n",
    "A good choice might be k = 15 (the real cluster number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'X1', y = 'X2', data = X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_inertias(X, 30, 1, kmc_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_s4 = pd.read_csv('Data/s4cluster.txt', delimiter = '\\s+ ', header = None, names = ['X1', 'X2'], engine = 'python')\n",
    "X_s4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = 'X1', y = 'X2', data = X_s4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Looks like a mess. But this kind of mess is typical.\n",
    "- A hexbin density plot reveals the clustering structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x= 'X1', y= 'X2', kind=\"hex\", data = X_s4, color=\"#4CB391\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_inertias(X_s4, 30, 1, kmc_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Doesn't work very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When there is a lot of overlap, sum of squared errors decreases smoothly with number of centroids.\n",
    "- Need a better/more meaningful metric to measure effectiveness of clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The silhouette coefficient\n",
    "A more principled way of measuring clustering effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"Images/silhouette_distance.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The notion of **cohesion**: \n",
    "- how tightly bound is a point in a given cluster to its cluster members?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Cohesiveness**\n",
    "\n",
    "$$ a(i) = \\overline{d(x_i, x_j)} $$ \n",
    "\n",
    "for $j$ indexing points in same clusters as point $i$.\n",
    "\n",
    "**Average of distance of $i$ to its clustermates.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The notion of **differentiation**: \n",
    "- how far away is a point in a given cluster from points in other clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Differentiation**\n",
    "\n",
    "$$ b(i) = \\overline{d(x_i, x_k)} $$ \n",
    "\n",
    "for $k$ indexing points in nearest neighboring cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Silhouette index\n",
    "\n",
    "Measuring binding of a point to its own cluster vs. neighboring cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Silhouette index for point $i$:\n",
    "$$ s(i) = \\frac{b(i) - a(i)}{\\max(a(i),b(i))} $$\n",
    "\n",
    "- When $a(i)$ is very small compared to $b(i)$:\n",
    "    - Point $i$ much more tightly bound to clustermates than neighboring cluster.\n",
    "    - $s(i) \\rightarrow 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When $a(i)$ is very large compared to $b(i)$:\n",
    "    - Point $i$ closer to points in neighboring cluster than its own.\n",
    "    - $s(i) \\rightarrow -1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Visualizing silhouette index for entire dataset:\n",
    "- cohesiveness/differentiation for each assigned cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's evaluate clustering on our trickiest clustering dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()), \n",
    "         ('kmc', KMeans(n_clusters = 15,n_init = 'auto') ) ]\n",
    "kmc_pipe = Pipeline(steps)\n",
    "X_s4['clstr_labels'] = kmc_pipe.fit_predict(X_s4[['X1', 'X2']])\n",
    "X_s4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_palette(\"tab10\")\n",
    "scld_centers = kmc_pipe['kmc'].cluster_centers_\n",
    "kc_centers = kmc_pipe['scaler'].inverse_transform(scld_centers)\n",
    "sns.scatterplot(x = 'X1', y = 'X2', hue = 'clstr_labels', palette=sns.color_palette('tab10', n_colors= 15), data = X_s4)\n",
    "sns.scatterplot(x = kc_centers[:,0], y = kc_centers[:,1], color = 'blue', s = 80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The fitted centroids and the centers of density line up well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x= 'X1', y= 'X2', kind=\"hex\", data = X_s4, color=\"#4CB391\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-learn can calculate silhouette index for each data point given cluster labels:\n",
    "\n",
    "- silhouette_samples(data, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let'd do this on our clustering result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "silhouette_samples(X_s4[['X1', 'X2']],\n",
    "                   X_s4['clstr_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_s4['silhouette'] = silhouette_samples(X_s4[['X1', 'X2']],\n",
    "                   X_s4['clstr_labels'])\n",
    "\n",
    "X_s4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One useful plot is a barplot of the average silhouette index for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "col_list = ['clstr_labels', 'silhouette']\n",
    "silh_idx_avgs = X_s4[col_list].groupby('clstr_labels').mean() #.sort_values(by = 'silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "silh_idx_avgs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A visual of the cohesion/differentiation by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = 'silhouette', \n",
    "            y = 'clstr_labels', orient = 'h',\n",
    "            data = silh_idx_avgs.reset_index())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The silhouette score**: average silhouette index over all samples\n",
    "- the better the clustering solution, the higher the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "s_score = silhouette_score(X_s4[['X1', 'X2']], X_s4['clstr_labels'])\n",
    "s_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An often used visual is the silhouette plot.\n",
    "- More information than average silhouette score by cluster.\n",
    "- Distribution of silhouette indices by cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def silhouette_plot(Xclustered_scores):\n",
    "    \n",
    "    n_clusters = 15\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (8,11))\n",
    "    \n",
    "    ax.set_xlim([-0.1, 1])\n",
    "    ax.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "    ax.axvline(x=s_score, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = Xclustered_scores[Xclustered_scores['clstr_labels'] == i].silhouette\n",
    "\n",
    "        ith_cluster_silhouette_values = ith_cluster_silhouette_values.sort_values(ascending = True)\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "\n",
    "    ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "silhouette_plot(X_s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Distribution of silhouette indices grouped by cluster.\n",
    "- Want all labels to be above the average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comparing plot by plot for each realization of $k$:\n",
    "- comprehensive but also may want a quick/dirty metric for tuning K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Plotting silhouette coefficient vs. K\n",
    "- Plot/metric for finding a plausible K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def plot_silh_scores(X, K, increment, kmc_pipe):\n",
    "\n",
    "    klist = np.arange(2,K,increment)\n",
    "    score_list = []\n",
    "    for k in klist:\n",
    "        kmc_pipe.steps.pop(-1)\n",
    "        kmc_pipe.steps.append(('kmc', \n",
    "                               KMeans(\n",
    "                                   n_clusters = k, n_init = 'auto')))\n",
    "        clstr_labels = kmc_pipe.fit_predict(X)\n",
    "\n",
    "        score = silhouette_score(X, clstr_labels)\n",
    "        score_list.append(score)\n",
    "        \n",
    "    sns.lineplot(x = klist, y = score_list, color = 'r')\n",
    "    plt.ylabel('Silhouette Coefficient')\n",
    "    plt.xlabel('K')\n",
    "    plt.title('Silhouette coefficient plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The maximum silhouette score is clearly at k = 15:\n",
    "- matches our exact cluster number even with our trickier dataset.\n",
    "- elbow plot tells us nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_silh_scores(X_s4[['X1', 'X2']], \n",
    "                 30, 1, kmc_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_inertias(X_s4[['X1', 'X2']], \n",
    "              30, 1, kmc_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### **Limitations** of $k$-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Ideal $k$-means scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ideal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### KMeans works well when:\n",
    "\n",
    "- Balanced cluster sizes\n",
    "- Clusters have similar density\n",
    "- Spherical clusters/equal variance of variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Problem Scenario 1 - classes not all round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "messyOne()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Problem Scenario 2 - imbalanced class size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "messyTwo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Problem Scenario 3 - class size and density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "messyThree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Solution to challenges:\n",
    "\n",
    "- Try different clustering methods:\n",
    "- e.g., Gaussian mixtures, DBSCAN, Hierarchical clustering, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### $k$ - means on larger dataset - Wine subscription\n",
    "\n",
    "You want to run a wine subscription service, but you have no idea about wine tasting notes. You are a person of science.\n",
    "You have a wine dataset of scientific measurements.\n",
    "If you know a customer likes a certain wine in the dataset, can you recommend other wines to the customer in the same cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Questions:\n",
    "- How many clusters are in the wine dataset?\n",
    "- What are the characteristics of each clusters?\n",
    "- What problems do you see potentially in the data?\n",
    "\n",
    "the dataset is `Wine.csv`\n",
    "\n",
    "Instructions:\n",
    "- First, remove customer_segment from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Work on problem here: Would scaling make a difference?\n",
    "wine = pd.read_csv('data/Wine.csv')\n",
    "wine.drop(columns=['Customer_Segment'], inplace=True)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review $k$-means steps\n",
    "1. Look at and clean data (if needed)\n",
    "2. Scale data\n",
    "3. Try various values of $k$\n",
    "4. Create an elbow plot and Silhouette coefficient plot to find best $k$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How many clusters fit the data?\n",
    "\n",
    "What can you tell me about them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<details>\n",
    "    <summary>One answer here</summary>\n",
    "    \n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler().fit(wine)\n",
    "wine_scaled = ss.transform(wine)\n",
    "silhouette_scores = []\n",
    "for j in range(2, 30):\n",
    "    clusters = KMeans(n_clusters=j, n_init ='auto', random_state=42)\n",
    "    cluster_labels = clusters.fit_predict(wine)\n",
    "    silhouette = metrics.silhouette_score(wine, cluster_labels)\n",
    "    silhouette_scores.append(silhouette)\n",
    "print(f'The best number of clusters is {np.argmax(silhouette_scores) + 2}') \n",
    "plot_inertias(wine_scaled, 30, 1, kmc_pipe)\n",
    "plot_silh_scores(wine_scaled, 30, 1, kmc_pipe)\n",
    "best = KMeans(n_clusters=2, n_init ='auto', random_state=42)\n",
    "wine['cluster'] = best.fit_predict(wine)\n",
    "print(wine.groupby('cluster').mean())\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dplearn",
   "language": "python",
   "name": "dplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
